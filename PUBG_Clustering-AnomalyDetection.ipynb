{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PUBG_Logo](assets/PUBG_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "* Employ Anomaly Detection algorithms on dataset.\n",
    "* Discuss pertinent results.\n",
    "\n",
    "## Background Information\n",
    "* Playerunknown's Battleground (PUBG) is a video game, which set the standard for preceding games in the Battle Royale Genre. The main goal is to SURVIVE at all costs.\n",
    "\n",
    "## Process:\n",
    "* Exploratory Data Analysis conducted utilizing various python packages (Numpy, Matplotlib, Pandas, and Plotly).\n",
    "* Anomaly Detection Algorithms (Sci-Kit Learn)\n",
    "    * Local Outlier Field\n",
    "    * Ellipitic Envelope\n",
    "    * Isolation Forest\n",
    "\n",
    "\n",
    "## Table of Contents:\n",
    "* Part I: Exploratory Data Analysis\n",
    "    * EDA\n",
    "* Part II: Anomaly Detection Algorithm\n",
    "    * Local Outlier Field\n",
    "    * Ellipitic Envelope\n",
    "    * Isolation Forest\n",
    "* Part III: Isolation Forest in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing / Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin by reading in the CSV file containing the data, and examining the data contents such as the number of features and rows. It seems there are 152 column entries (features) and 87898 row entries (number of samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- Pandas Dataframe\n",
    "## Read in CSV\n",
    "orig = pd.read_csv('data/PUBG_Player_Statistics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us remove and combine features, which do not pertain to our goal of clustering solo player behavior. \n",
    "\n",
    "Remove:\n",
    "* player_name\n",
    "* tracker_id\n",
    "* duo\n",
    "* squad\n",
    "\n",
    "Add:\n",
    "* Total Distance\n",
    "\n",
    "This can be achieved by removing all columns after the 52nd. Also, create a new feature that combines the walking and riding distance.\n",
    "\n",
    "Also, we will reduce the variance in the data by removing players with less than the mean number of rounds in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------Preprocessing\n",
    "## Create a copy of the dataframe\n",
    "df = orig.copy()\n",
    "cols = np.arange(52, 152, 1)\n",
    "\n",
    "# Drop entries if they have null values\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "## Drop columns after the 52nd index\n",
    "df.drop(df.columns[cols], axis = 1, inplace = True)\n",
    "\n",
    "## Drop player_name and tracker id\n",
    "df.drop(df.columns[[0, 1]], axis = 1, inplace = True)\n",
    "\n",
    "## Drop Knockout and Revives\n",
    "df.drop(df.columns[[49]], axis = 1, inplace = True)\n",
    "df.drop(columns = ['solo_Revives'], inplace = True)\n",
    "\n",
    "## Drop the string solo from all strings\n",
    "df.rename(columns = lambda x: x.lstrip('solo_').rstrip(''), inplace = True)\n",
    "\n",
    "## Combine a few columns \n",
    "df['TotalDistance'] = df['WalkDistance'] + df['RideDistance']\n",
    "df['AvgTotalDistance'] = df['AvgWalkDistance'] + df['AvgRideDistance']\n",
    "\n",
    "# Remove Outliers\n",
    "df = df.drop(df[df['RoundsPlayed'] < df['RoundsPlayed'].mean()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into three sets: train, dev, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples is 20771\n",
      "The number of development samples is 7121\n",
      "The number of testing samples is 1781\n"
     ]
    }
   ],
   "source": [
    "# Create train and test set using Sci-Kit Learn\n",
    "train, test = train_test_split(df, test_size=0.3, random_state = 10)\n",
    "dev, test = train_test_split(test, test_size = 0.2, random_state = 10)\n",
    "data = train\n",
    "\n",
    "print(\"The number of training samples is\", len(train))\n",
    "print(\"The number of development samples is\", len(dev))\n",
    "print(\"The number of testing samples is\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important we go through the final output to make sure that are data preprocessing is complete. And it looks great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       KillDeathRatio      WinRatio  TimeSurvived  RoundsPlayed          Wins  \\\n",
      "count    20771.000000  20771.000000  2.077100e+04  20771.000000  20771.000000   \n",
      "mean         1.289158      2.204012  1.484172e+05    174.985894      3.554475   \n",
      "std          0.602602      2.510500  9.339460e+04    113.147056      4.939222   \n",
      "min          0.100000      0.000000  3.813548e+04     80.000000      0.000000   \n",
      "25%          0.900000      0.680000  9.091498e+04    104.000000      1.000000   \n",
      "50%          1.160000      1.460000  1.195404e+05    139.000000      2.000000   \n",
      "75%          1.520000      2.910000  1.733681e+05    205.000000      4.000000   \n",
      "max         17.410000     40.210000  1.219536e+06   1552.000000    102.000000   \n",
      "\n",
      "       WinTop10Ratio        Top10s    Top10Ratio        Losses        Rating  \\\n",
      "count   20771.000000  20771.000000  20771.000000  20771.000000  20771.000000   \n",
      "mean        0.138708     23.884743     14.369067    171.431419   2059.159131   \n",
      "std         0.137145     19.214653      7.396966    111.734872    256.747029   \n",
      "min         0.000000      1.000000      0.700000     58.000000   1165.510000   \n",
      "25%         0.040000     13.000000      9.300000    101.000000   1882.635000   \n",
      "50%         0.100000     19.000000     12.800000    136.000000   2074.280000   \n",
      "75%         0.200000     28.000000     17.600000    201.000000   2240.980000   \n",
      "max         1.000000    386.000000     69.300000   1541.000000   2967.090000   \n",
      "\n",
      "         BestRating      DamagePg  HeadshotKillsPg       HealsPg  \\\n",
      "count  20771.000000  20771.000000     20771.000000  20771.000000   \n",
      "mean    2084.405850    152.375769         0.269829      1.387851   \n",
      "std      248.783836     58.102445         0.171563      0.613690   \n",
      "min     1279.220000     15.590000         0.010000      0.070000   \n",
      "25%     1909.505000    113.610000         0.170000      1.020000   \n",
      "50%     2100.270000    141.620000         0.230000      1.280000   \n",
      "75%     2257.935000    178.490000         0.330000      1.620000   \n",
      "max     2963.690000   1054.120000         5.220000     15.720000   \n",
      "\n",
      "            KillsPg  MoveDistancePg  RevivesPg   RoadKillsPg   TeamKillsPg  \\\n",
      "count  20771.000000    20771.000000    20771.0  20771.000000  20771.000000   \n",
      "mean       1.249489     2564.498896        0.0      0.018677      0.007097   \n",
      "std        0.534357      914.865530        0.0      0.019422      0.008446   \n",
      "min        0.100000      603.150000        0.0      0.000000      0.000000   \n",
      "25%        0.890000     1939.505000        0.0      0.010000      0.000000   \n",
      "50%        1.140000     2393.870000        0.0      0.010000      0.010000   \n",
      "75%        1.480000     2988.270000        0.0      0.030000      0.010000   \n",
      "max       10.410000    14527.380000        0.0      0.350000      0.160000   \n",
      "\n",
      "       TimeSurvivedPg      Top10sPg         Kills       Assists      Suicides  \\\n",
      "count    20771.000000  20771.000000  20771.000000  20771.000000  20771.000000   \n",
      "mean       866.861773      0.143653    212.706129     13.568533      1.189302   \n",
      "std        165.230571      0.074049    169.973630     10.984160      1.520992   \n",
      "min        384.860000      0.010000     20.000000      0.000000      0.000000   \n",
      "25%        751.730000      0.090000    119.000000      7.000000      0.000000   \n",
      "50%        855.710000      0.130000    166.000000     11.000000      1.000000   \n",
      "75%        966.225000      0.180000    247.000000     16.000000      2.000000   \n",
      "max       1669.600000      0.690000   4023.000000    185.000000     67.000000   \n",
      "\n",
      "          TeamKills  HeadshotKills  HeadshotKillRatio  VehicleDestroys  \\\n",
      "count  20771.000000   20771.000000       20771.000000     20771.000000   \n",
      "mean       1.189351      45.870011           0.208889         1.556930   \n",
      "std        1.521128      43.602108           0.053425         2.605163   \n",
      "min        0.000000       2.000000           0.040000         0.000000   \n",
      "25%        0.000000      23.000000           0.170000         0.000000   \n",
      "50%        1.000000      34.000000           0.210000         1.000000   \n",
      "75%        2.000000      54.000000           0.240000         2.000000   \n",
      "max       67.000000    1494.000000           0.760000       138.000000   \n",
      "\n",
      "          RoadKills    DailyKills   WeeklyKills  RoundMostKills  \\\n",
      "count  20771.000000  20771.000000  20771.000000    20771.000000   \n",
      "mean       3.249242      8.490925     21.468538        8.319002   \n",
      "std        4.340528     10.347829     27.086182        2.941070   \n",
      "min        0.000000      0.000000      0.000000        2.000000   \n",
      "25%        1.000000      2.000000      6.000000        6.000000   \n",
      "50%        2.000000      5.000000     13.000000        8.000000   \n",
      "75%        4.000000     11.000000     27.000000       10.000000   \n",
      "max      171.000000    174.000000    491.000000       87.000000   \n",
      "\n",
      "       MaxKillStreaks  WeaponAcquired          Days  LongestTimeSurvived  \\\n",
      "count    20771.000000         20771.0  20771.000000         20771.000000   \n",
      "mean         2.468634             0.0     33.988012          2025.299524   \n",
      "std          1.347912             0.0     12.724328           103.533922   \n",
      "min          1.000000             0.0      4.000000          1612.800000   \n",
      "25%          2.000000             0.0     25.000000          1960.120000   \n",
      "50%          2.000000             0.0     32.000000          1991.500000   \n",
      "75%          3.000000             0.0     40.000000          2100.150000   \n",
      "max         87.000000             0.0    173.000000          3067.930000   \n",
      "\n",
      "       MostSurvivalTime  AvgSurvivalTime     WinPoints  WalkDistance  \\\n",
      "count      20771.000000     20771.000000  20771.000000  2.077100e+04   \n",
      "mean        2025.299524       906.716177   3085.571037  2.183727e+05   \n",
      "std          103.533922       210.977929   1536.193318  1.403832e+05   \n",
      "min         1612.800000       242.940000    959.000000  4.848569e+04   \n",
      "25%         1960.120000       761.985000   1803.000000  1.339626e+05   \n",
      "50%         1991.500000       888.930000   2764.000000  1.767646e+05   \n",
      "75%         2100.150000      1038.490000   3952.000000  2.553466e+05   \n",
      "max         3067.930000      1797.320000  10143.000000  2.457887e+06   \n",
      "\n",
      "       RideDistance  MoveDistance  AvgWalkDistance  AvgRideDistance  \\\n",
      "count  2.077100e+04  2.077100e+04     20771.000000     20771.000000   \n",
      "mean   2.230056e+05  4.413784e+05      1346.563388      1354.913718   \n",
      "std    2.099482e+05  3.280358e+05       494.991381       858.724381   \n",
      "min    5.001280e+03  6.091792e+04       236.830000        30.810000   \n",
      "25%    1.051215e+05  2.486792e+05      1068.300000       745.990000   \n",
      "50%    1.637230e+05  3.458146e+05      1293.540000      1157.880000   \n",
      "75%    2.662136e+05  5.169522e+05      1558.880000      1744.530000   \n",
      "max    3.453278e+06  4.592642e+06     28756.940000      9127.700000   \n",
      "\n",
      "        LongestKill         Heals        Boosts    DamageDealt  TotalDistance  \\\n",
      "count  20771.000000  20771.000000  20771.000000   20771.000000   2.077100e+04   \n",
      "mean     324.427150    243.003226    215.759087   26040.816089   4.413784e+05   \n",
      "std      118.718927    204.151779    172.743355   19913.848424   3.280358e+05   \n",
      "min       19.820000     23.000000      9.000000    3219.700000   6.091792e+04   \n",
      "25%      250.585000    129.000000    115.000000   14826.670000   2.486791e+05   \n",
      "50%      306.840000    185.000000    167.000000   20426.280000   3.458145e+05   \n",
      "75%      375.460000    284.000000    255.000000   30325.895000   5.169522e+05   \n",
      "max     4694.110000   6341.000000   2923.000000  442283.700000   4.592642e+06   \n",
      "\n",
      "       AvgTotalDistance  \n",
      "count      20771.000000  \n",
      "mean        2701.477106  \n",
      "std         1112.561617  \n",
      "min          354.890000  \n",
      "25%         1936.070000  \n",
      "50%         2506.620000  \n",
      "75%         3267.805000  \n",
      "max        30077.250000  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', 52):\n",
    "    print(data.describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only factors above which have a positive correlation to average survival time are Average Total Distance, Win Ratio, and Top 10 Ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure: \n",
    "* LoF\n",
    "    * 3D\n",
    "* Elliptic\n",
    "    * 3D\n",
    "* IsolatorForest\n",
    "    * 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Clustering in 3D (Selected Few Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected the following features because of experts and my domain experience playing PUBG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select four features\n",
    "train_data = train.loc[:,['WinRatio', 'KillDeathRatio', \"HeadshotKillRatio\", \"Top10Ratio\"]]\n",
    "dev_data = dev.loc[:, ['WinRatio', 'KillDeathRatio', \"HeadshotKillRatio\", \"Top10Ratio\"]]\n",
    "test_data = test.loc[:, ['WinRatio', 'KillDeathRatio', \"HeadshotKillRatio\", \"Top10Ratio\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is utilized to make sure all features are normalized and have similar orders of magnitude. This is important because our clustering algorithms look into calculating the distance between points. In our case, we employed a zero-mean and unit-variance scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data (Normaliz)\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(train_data)\n",
    "X_dev_std = scaler.transform(dev_data)\n",
    "X_test_std = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Outlier Factor\n",
    "\n",
    "LOF compares outliers to their local neighborhood rather than the global data distribution. Because the density around an outlier object is different than the density around the neighbors. The method involves using the relative density of an object against its neighbors as indicator of the degree of the object being outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithm\n",
    "1. Arbitrarily select a point P.\n",
    "2. Calculate distances between P and every other point.\n",
    "3. Find the Kth closest point\n",
    "4. Find K closest points whose distances are smaller than the Kth point.\n",
    "5. Find its Local Reachability Density (how close its neighbors are to it), the lower the density, the farther p from its neighbors.\n",
    "6. Find its local outlier factor, the sum of the distances between P and its neighboring points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters\n",
    "\n",
    "In LOF, we'll be examining two parameters:\n",
    "* contamination: proportion of outliers in a dataset. \n",
    "* num_neighbors (K): the minimum number of points to form a dense region.\n",
    "\n",
    "For contamination: We'll be making an educated guess given this article stating that out of 26,000,000 accounts, 1,500,000 were caught cheating ~ 0.58% [1]. However, this does not include the people who didnt get caught with cheating. \n",
    "\n",
    "For num_neighbors: We'll be using a research paper on LOF to select the k-number of neearest neighbors. If you want to consider a point near a group of N points as an outlier, rather than part of that group, your k value should be at least N, ~2000 [2]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with configuring all parameters for LOF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOF = LocalOutlierFactor(n_neighbors = 20, contamination = 0.0058)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = LOF.fit_predict(X_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette analysis studies how similar and dissimilar neighboring cluster centroids are. We select the point which is closest to +1. In our case, the parameters have a silhouette score of 0.7332."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Silhouette Score for the training set is 0.5318327170584771.\n"
     ]
    }
   ],
   "source": [
    "# Print Silhouette Score\n",
    "ss = metrics.silhouette_score(X_train_std, labels)\n",
    "print('The Silhouette Score for the training set is ' + str(ss) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load in our function to plot our 3D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter3d_cluster(df, x, y, z, code, title):\n",
    "    scatter = px.scatter_3d(df, x=x, y=y, z=z, color = code,  \n",
    "                            color_discrete_sequence=px.colors.qualitative.Light24)\n",
    "    \n",
    "    scatter.update_layout(title = title, title_font = dict(size = 30),\n",
    "                          scene = dict(\n",
    "                              xaxis = dict(\n",
    "                                  backgroundcolor=\"rgb(200, 200, 230)\",\n",
    "                                  gridcolor=\"white\",\n",
    "                                  showbackground=True,\n",
    "                                  zerolinecolor=\"white\",\n",
    "                                  nticks=10, ticks='outside',\n",
    "                                  tick0=0, tickwidth = 4,\n",
    "                                  title_font = dict(size = 16)),\n",
    "                              yaxis = dict(\n",
    "                                  backgroundcolor=\"rgb(230, 200,230)\",\n",
    "                                  gridcolor=\"white\",\n",
    "                                  showbackground=True,\n",
    "                                  zerolinecolor=\"white\",\n",
    "                                  nticks=10, ticks='outside',\n",
    "                                  tick0=0, tickwidth = 4,\n",
    "                                  title_font = dict(size = 16)),\n",
    "                              zaxis = dict(\n",
    "                                  backgroundcolor=\"rgb(230, 230,200)\",\n",
    "                                  gridcolor=\"white\",\n",
    "                                  showbackground=True,\n",
    "                                  zerolinecolor=\"white\",\n",
    "                                  nticks=10, ticks='outside',\n",
    "                                  tick0=0, tickwidth = 4,\n",
    "                                  title_font = dict(size = 16),\n",
    "                              ),\n",
    "                          ),\n",
    "                          width = 700\n",
    "                         )\n",
    "    return scatter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, plot the data and let's label the data with our assumptions on how hackers are perceived.\n",
    "\n",
    "Hackers tend to have high Kill-Death Ratios, Headshot-Kill Ratios, Top 10 Ratios, and Win Ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 3D Plot of Training Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_train_std = pd.DataFrame(X_train_std)\n",
    "df_X_train_std['Cluster'] = pd.Series(labels, index = df_X_train_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {1: \"Human\", -1: \"Hacker\"}\n",
    "df_X_train_std['Cluster_Labels'] = df_X_train_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_train_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_std['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 20650 humans and 121 hackers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_train_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting on the dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with predicting on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOF = LocalOutlierFactor(n_neighbors = 2000, contamination = 0.0058, novelty = True).fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_labels = LOF.predict(X_dev_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the 3D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Plot of deving Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_dev_std = pd.DataFrame(X_dev_std)\n",
    "df_X_dev_std['Cluster'] = pd.Series(predict_labels, index=df_X_dev_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {1: \"Human\", -1: \"Hacker\"}\n",
    "df_X_dev_std['Cluster_Labels'] = df_X_dev_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_dev_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio' )\n",
    "\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 7072 humans and 49 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_dev_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with predicting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOF = LocalOutlierFactor(n_neighbors = 2000, contamination = 0.0058, novelty = True).fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_labels = LOF.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the 3D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Plot of testing Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_test_std = pd.DataFrame(X_test_std)\n",
    "df_X_test_std['Cluster'] = pd.Series(predict_labels, index = df_X_test_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {1: \"Human\", -1: \"Hacker\"}\n",
    "df_X_test_std['Cluster_Labels'] = df_X_test_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_test_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 1768 humans and 13 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_test_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elliptic Envelope\n",
    "\n",
    "Assumes the data is Gaussian and learns an ellipse. The model fits a multivariate Gaussian density to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithm [3]\n",
    "1. Draw a random h-subset\n",
    "2. Draw a random (p +1) subset J and then compute the covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters\n",
    "\n",
    "In EE, we'll be examining two parameters:\n",
    "* contamination: proportion of outliers in a dataset. \n",
    "\n",
    "For contamination: We'll be making an educated guess given this article stating that out of 26,000,000 accounts, 1,500,000 were caught cheating ~ 0.58% [1]. However, this does not include the people who didnt get caught with cheating. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with configuring all parameters for EE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE = EllipticEnvelope(random_state = 10, contamination = 0.0058).fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = EE.fit_predict(X_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette analysis studies how similar and dissimilar neighboring cluster centroids are. We select the point which is closest to +1. In our case, the parameters have a silhouette score of 0.7427."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = metrics.silhouette_score(X_train_std, labels)\n",
    "print('The Silhouette Score for the training set is ' + str(ss) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 3D Plot of Training Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_train_std = pd.DataFrame(X_train_std)\n",
    "df_X_train_std['Cluster'] = pd.Series(labels, index = df_X_train_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {1: \"Human\", -1: \"Hacker\"}\n",
    "df_X_train_std['Cluster_Labels'] = df_X_train_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_train_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_std['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 20650 humans and 121 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_train_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting on the dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with predicting on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE = EllipticEnvelope(random_state = 10, contamination = 0.0058).fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_labels = EE.predict(X_dev_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the 3D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Plot of deving Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_dev_std = pd.DataFrame(X_dev_std)\n",
    "df_X_dev_std['Cluster'] = pd.Series(predict_labels, index=df_X_dev_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {1: \"Human\", -1: \"Hacker\"}\n",
    "df_X_dev_std['Cluster_Labels'] = df_X_dev_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_dev_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio' )\n",
    "\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 7073 humans and 48 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_dev_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with predicting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE = EllipticEnvelope(random_state = 10, contamination = 0.0058).fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_labels = EE.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the 3D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Plot of testing Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_test_std = pd.DataFrame(X_test_std)\n",
    "df_X_test_std['Cluster'] = pd.Series(predict_labels, index = df_X_test_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {1: \"Human\", -1: \"Hacker\"}\n",
    "df_X_test_std['Cluster_Labels'] = df_X_test_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_test_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 1770 humans and 11 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_X_test_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolation Forest\n",
    "\n",
    "The algorithm isolates each point in the data and splits them into outliers or inliers. The split depends on how long it takes to separate the points. If the point is an outlier, it will be easy to split, but if the point is an inlier, it will be difficult to isolate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithm [4]\n",
    "1. Select the point to isolate.\n",
    "2. For each feature, set the range to isolate between the minimum and the maximum.\n",
    "3. Choose a feature randomly.\n",
    "4. Pick a value that’s in the range, again randomly:\n",
    "    * If the chosen value keeps the point above, switch the minimum of the range of the feature to the value.\n",
    "    * If the chosen value keeps the point below, switch the maximum of the range of the feature to the value.\n",
    "5. Repeat steps 3 & 4 until the point is isolated. That is, until the point is the only one which is inside the range for all features.\n",
    "6. Count how many times you’ve had to repeat steps 3 & 4. We call this quantity the isolation number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters\n",
    "\n",
    "In IF, we'll be examining three parameters:\n",
    "* contamination: proportion of outliers in a dataset.\n",
    "* max_samples: The number of samples to draw from X to train each base estimator.\n",
    "* n_estimators: The number of base estimators in the ensemble.\n",
    "\n",
    "For contamination: We'll be making an educated guess given this article stating that out of 26,000,000 accounts, 1,500,000 were caught cheating ~ 0.58% [1]. However, this does not include the people who didnt get caught with cheating. \n",
    "\n",
    "For max_samples: We'll be setting the max_samples to auto ~ 256 samples.\n",
    "\n",
    "For n_estimators: We'll be setting the n_estimators to 500.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with configuring all parameters for IF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF = IsolationForest(max_samples = 'auto' ,random_state = 10, contamination = .0058, n_estimators = 500) \n",
    "IF.fit(X_train_std)\n",
    "IF_scores = IF.decision_function(X_train_std)\n",
    "IF_anomalies = IF.predict(X_train_std)\n",
    "IF_anomalies = pd.Series(IF_anomalies).replace([-1,1], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = IF_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.value_counts(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette analysis studies how similar and dissimilar neighboring cluster centroids are. We select the point which is closest to +1. In our case, the parameters have a silhouette score of 0.7440."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = metrics.silhouette_score(X_train_std, labels)\n",
    "print('The Silhouette Score for the training set is ' + str(ss) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 3D Plot of Training Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_train_std = pd.DataFrame(X_train_std)\n",
    "df_X_train_std['Cluster'] = pd.Series(labels, index = df_X_train_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Human\", 1: \"Hacker\"}\n",
    "df_X_train_std['Cluster_Labels'] = df_X_train_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_train_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_train_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_std['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 20650 humans and 121 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_train_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting on the dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with predicting on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF = IsolationForest(max_samples = 'auto' ,random_state = 10, contamination = .0058, n_estimators = 500) \n",
    "IF.fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF_anomalies = IF.predict(X_dev_std)\n",
    "IF_anomalies = pd.Series(IF_anomalies).replace([-1,1], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = IF_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the 3D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Plot of deving Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_dev_std = pd.DataFrame(X_dev_std)\n",
    "df_X_dev_std['Cluster'] = pd.Series(predict_labels, index=df_X_dev_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Human\", 1: \"Hacker\"}\n",
    "df_X_dev_std['Cluster_Labels'] = df_X_dev_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_dev_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio' )\n",
    "\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_dev_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 7071 humans and 50 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_dev_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with predicting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF = IsolationForest(max_samples = 'auto' ,random_state = 10, contamination = .0058, n_estimators = 500) \n",
    "IF.fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF_anomalies = IF.predict(X_test_std)\n",
    "IF_anomalies = pd.Series(IF_anomalies).replace([-1,1], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = IF_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the 3D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Plot of testing Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_test_std = pd.DataFrame(X_test_std)\n",
    "df_X_test_std['Cluster'] = pd.Series(predict_labels, index = df_X_test_std.index)\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Human\", 1: \"Hacker\"}\n",
    "df_X_test_std['Cluster_Labels'] = df_X_test_std['Cluster'].map(cluster_label_names)  \n",
    "\n",
    "df_X_test_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\",\n",
    "                          \"Top 10 Ratio\", 'Cluster', 'Cluster_Labels']\n",
    "\n",
    "# Plots of Win Ratio, Kill Death Ratio, Headshott KIll Ratio\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Headshot-Kill Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Kill Death Ratio', \n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                  title = 'Clustering of Kill-Death Ratio, Top 10 Ratio, and Win Ratio')\n",
    "\n",
    "scatter3d_cluster(df = df_X_test_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', z = 'Win Ratio', code = 'Cluster_Labels', \n",
    "                 title = 'Clustering of Headshot-Kill Ratio, Top 10 Ratio, and Win Ratio') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 1769 humans and 12 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_X_test_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our best performing anomaly detection algorithm Isolation Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with configuring all parameters for Isolation Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest on Training Data\n",
    "IF = IsolationForest(max_samples = 'auto' ,random_state = 10, contamination = .0058, n_estimators = 500) \n",
    "IF.fit(X_train_std)\n",
    "IF_scores = IF.decision_function(X_train_std)\n",
    "IF_anomalies = IF.predict(X_train_std)\n",
    "IF_anomalies = pd.Series(IF_anomalies).replace([-1,1], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = IF_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the function below to create our 2D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter2d_cluster(df, x, y,  code, title):\n",
    "    scatter = px.scatter(df, x = x, y = y, color = code,\n",
    "                         color_discrete_sequence = px.colors.qualitative.Light24)\n",
    "    \n",
    "    scatter.update_xaxes(showline = True, linewidth = 1, linecolor = 'black', \n",
    "                          mirror = True, gridcolor = 'LightPink', automargin = True, \n",
    "                          zeroline = True, zerolinewidth = 2, zerolinecolor = 'LightPink', \n",
    "                          ticks = \"outside\", tickwidth = 2, tickcolor = 'black', ticklen = 10,\n",
    "                          title_font = dict(size = 18))\n",
    "    scatter.update_yaxes(showline = True, linewidth = 2, linecolor = 'black', \n",
    "                          mirror = True, gridcolor = 'LightPink',\n",
    "                          zeroline = True, zerolinewidth = 1, zerolinecolor = 'LightPink', \n",
    "                          ticks = \"outside\", tickwidth = 2, tickcolor = 'black', ticklen = 10,\n",
    "                          title_font = dict(size = 18))\n",
    "    \n",
    "    \n",
    "    scatter.update_layout(title = title, title_font = dict(size = 24), \n",
    "                          legend = dict(\n",
    "                              x = 1,\n",
    "                              y = 1,\n",
    "                              traceorder = \"normal\",\n",
    "                              font = dict(\n",
    "                                  family = \"sans-serif\",\n",
    "                                  size = 14,\n",
    "                                  color = \"black\"\n",
    "                              ),\n",
    "                              bgcolor = \"#e5ecf6\",\n",
    "                              bordercolor = \"Black\",\n",
    "                              borderwidth = 2\n",
    "                          )\n",
    "                         )\n",
    "    return scatter.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll populate our scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D Plot of Training Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_train_std = pd.DataFrame(X_train_std)\n",
    "df_X_train_std['cluster'] = pd.Series(labels, index = df_X_train_std.index)\n",
    "df_X_train_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\", \"Top 10 Ratio\", 'cluster']\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Human\", 1: \"Hacker\"}\n",
    "df_X_train_std['Cluster_Labels'] = df_X_train_std['cluster'].map(cluster_label_names)  \n",
    "\n",
    "\n",
    "# Plots of Win Ratio, KDR, Headshott KIll Ratio\n",
    "scatter2d_cluster(df = df_X_train_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Win Ratio',  code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Win Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_train_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Headshot Kill Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_train_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Win Ratio',  code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Headshot Kill Ratio and Win Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_train_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Top 10 Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Top 10 Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_train_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Headshot Kill Ratio and Top 10 Ratio')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 20650 humans and 121 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting on the dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with predicting on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF = IsolationForest(max_samples = 'auto' ,random_state = 10, contamination = .0058, n_estimators = 500) \n",
    "IF.fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF_anomalies = IF.predict(X_dev_std)\n",
    "IF_anomalies = pd.Series(IF_anomalies).replace([-1,1], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = IF_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, populate our 2D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Plot of Testing Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_dev_std = pd.DataFrame(X_dev_std)\n",
    "df_X_dev_std['cluster'] = pd.Series(predict_labels, index = df_X_dev_std.index)\n",
    "df_X_dev_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\", \"Top 10 Ratio\", 'cluster']\n",
    "\n",
    "# Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Human\", 1: \"Hacker\"}\n",
    "df_X_dev_std['Cluster_Labels'] = df_X_dev_std['cluster'].map(cluster_label_names)  \n",
    "\n",
    "\n",
    "# Plots of Win Ratio, KDR, Headshott KIll Ratio\n",
    "scatter2d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Win Ratio',  code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Win Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Headshot Kill Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_dev_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Win Ratio',  code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Headshot Kill Ratio and Win Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_dev_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Top 10 Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Top 10 Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_dev_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Headshot Kill Ratio and Top 10 Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 7071 humans and 50 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X_dev_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with predicting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF = IsolationForest(max_samples = 'auto' ,random_state = 10, contamination = .0058, n_estimators = 500) \n",
    "IF.fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF_anomalies = IF.predict(X_test_std)\n",
    "IF_anomalies = pd.Series(IF_anomalies).replace([-1,1], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = IF_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, populate our 2D scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D Plot of Testing Data\n",
    "# Create and modify dataframe for the cluster column\n",
    "df_X_test_std = pd.DataFrame(X_test_std)\n",
    "df_X_test_std['cluster'] = pd.Series(predict_labels, index=df_X_test_std.index)\n",
    "df_X_test_std.columns = ['Win Ratio', 'Kill Death Ratio', \"Headshot Kill Ratio\", \"Top 10 Ratio\", 'cluster']\n",
    "\n",
    "#Rename Cluster label names from k-means\n",
    "cluster_label_names = {0: \"Human\", 1: \"Hacker\"}\n",
    "df_X_test_std['Cluster_Labels'] = df_X_test_std['cluster'].map(cluster_label_names)  \n",
    "\n",
    "\n",
    "# Plots of Win Ratio, KDR, Headshott KIll Ratio\n",
    "scatter2d_cluster(df = df_X_test_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Win Ratio',  code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Win Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_test_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Headshot Kill Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Headshot Kill Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_test_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Win Ratio',  code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Headshot Kill Ratio and Win Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_test_std , x = 'Kill Death Ratio',\n",
    "                  y = 'Top 10 Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Kill Death Ratio and Top 10 Ratio')\n",
    "\n",
    "scatter2d_cluster(df = df_X_test_std , x = 'Headshot Kill Ratio',\n",
    "                  y = 'Top 10 Ratio', code = 'Cluster_Labels',\n",
    "                  title = 'Clustering of Headshot Kill Ratio and Top 10 Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we observed roughly 1769 humans and 12 hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_X_test_std.groupby('Cluster_Labels').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "* Without external labels, we cannot verify the accuracy of these clusters. But we can make an educated guess on what these clusters are by using domain experience and advice from experts playing the game.\n",
    "* Treating this problem as an outlier detection (anomaly detection) problem has yielded promising results.\n",
    "    * With the assumption that the number of hackers in our population is low, we can treat them as outliers.\n",
    "* However, most of the outliers in our models can be misclassifying actual humans, so further tuning needs to be done to reduce that misclassification rate.\n",
    "* In terms of algorithm performance - the algorithms were rated based on the Silhouette Score and Possible Misclassification\n",
    "    * Isolation Forest > Elipitical Envelope > LOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] https://gamerant.com/playerunknowns-battlegrounds-cheater-ban-count/\n",
    "\n",
    "[2] M. Breunig, H. Kriegel, R. Ng and J. Sander, \"LOF\", ACM SIGMOD Record, vol. 29, no. 2, pp. 93-104, 2000. Available: 10.1145/335191.335388.\n",
    "\n",
    "[3] P. J. Rousseeuw and K. V. Driessen, “A Fast Algorithm for the Minimum Covariance Determinant Estimator,” Technometrics, vol. 41, no. 3, pp. 212–223, 1999.\n",
    "\n",
    "[4] K. M. Ting, “Adaptive Anomaly Detection using Isolation Forest,” 2009. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
